{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c54d6be1-77bc-4090-a7c8-5b0c31fc331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final dataset for recommendations: (2500, 4)\n",
      "                  title   main_director release_date  \\\n",
      "0               Minions      Kyle Balda   2015-06-17   \n",
      "1          Wonder Woman   Patty Jenkins   2017-05-30   \n",
      "2  Beauty and the Beast     Bill Condon   2017-03-16   \n",
      "3           Baby Driver    Edgar Wright   2017-06-28   \n",
      "4            Big Hero 6  Chris Williams   2014-10-24   \n",
      "\n",
      "                                                soup  \n",
      "0  assist aftercreditssting duringcreditssting ev...  \n",
      "1  dccomic hero greekmytholog island worldwari su...  \n",
      "2  franc magic castl fairytal music curs anthropo...  \n",
      "3  robberi atlanta music crimeboss romanc tinnitu...  \n",
      "4  brotherbrotherrelationship hero talent reveng ...  \n",
      "\n",
      "Shape of the Count Matrix: (2500, 1916)\n",
      "\n",
      "Computing Cosine Similarity Matrix...\n",
      "Cosine Similarity Matrix Computed.\n",
      "Cosine Similarity Matrix saved to 'cosine_similarity_matrix.csv'\n",
      "\n",
      "--- Movie Recommendations ---\n",
      "\n",
      "Recommended movies for \"Minions\":\n",
      "- Title: Penguins of Madagascar\n",
      "  Director: Eric Darnell\n",
      "  Release Date: 2014-11-22\n",
      "\n",
      "- Title: Wreck-It Ralph\n",
      "  Director: Rich Moore\n",
      "  Release Date: 2012-11-01\n",
      "\n",
      "- Title: Alvin and the Chipmunks: The Road Chip\n",
      "  Director: Walt Becker\n",
      "  Release Date: 2015-12-17\n",
      "\n",
      "- Title: MacGruber\n",
      "  Director: Jorma Taccone\n",
      "  Release Date: 2010-05-21\n",
      "\n",
      "- Title: Finding Nemo\n",
      "  Director: Andrew Stanton\n",
      "  Release Date: 2003-05-30\n",
      "\n",
      "- Title: Harold & Kumar Escape from Guantanamo Bay\n",
      "  Director: Jon Hurwitz\n",
      "  Release Date: 2008-04-25\n",
      "\n",
      "- Title: Bolt\n",
      "  Director: Chris Williams\n",
      "  Release Date: 2008-11-21\n",
      "\n",
      "- Title: George of the Jungle 2\n",
      "  Director: David Grossman\n",
      "  Release Date: 2003-08-18\n",
      "\n",
      "- Title: Brave\n",
      "  Director: Brenda Chapman\n",
      "  Release Date: 2012-06-21\n",
      "\n",
      "- Title: Despicable Me 3\n",
      "  Director: Kyle Balda\n",
      "  Release Date: 2017-06-15\n",
      "\n",
      "\n",
      "Recommended movies for \"Avatar\":\n",
      "- Title: Aliens\n",
      "  Director: James Cameron\n",
      "  Release Date: 1986-07-18\n",
      "\n",
      "- Title: Terminator 2: Judgment Day\n",
      "  Director: James Cameron\n",
      "  Release Date: 1991-07-01\n",
      "\n",
      "- Title: The Terminator\n",
      "  Director: James Cameron\n",
      "  Release Date: 1984-10-26\n",
      "\n",
      "- Title: True Lies\n",
      "  Director: James Cameron\n",
      "  Release Date: 1994-07-14\n",
      "\n",
      "- Title: Titanic\n",
      "  Director: James Cameron\n",
      "  Release Date: 1997-11-18\n",
      "\n",
      "- Title: Jupiter Ascending\n",
      "  Director: Lilly Wachowski\n",
      "  Release Date: 2015-02-04\n",
      "\n",
      "- Title: Frank Herbert's Dune\n",
      "  Director: John Harrison\n",
      "  Release Date: 2000-12-03\n",
      "\n",
      "- Title: Star Trek Into Darkness\n",
      "  Director: J.J. Abrams\n",
      "  Release Date: 2013-05-05\n",
      "\n",
      "- Title: John Carter\n",
      "  Director: Andrew Stanton\n",
      "  Release Date: 2012-03-07\n",
      "\n",
      "- Title: Thunderbirds\n",
      "  Director: Jonathan Frakes\n",
      "  Release Date: 2004-07-23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ast import literal_eval\n",
    "import zipfile\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "keywords_zip_path = \"keywords.csv.zip\"\n",
    "movies_metadata_zip_path = \"movies_metadata.csv.zip\"\n",
    "credits_zip_path = \"credits.csv.zip\"\n",
    "links_csv_path = \"links.csv\"\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(keywords_zip_path, 'r') as zip_ref:\n",
    "        keywords_df = pd.read_csv(zip_ref.open(zip_ref.namelist()[0]))\n",
    "\n",
    "    with zipfile.ZipFile(movies_metadata_zip_path, 'r') as zip_ref:\n",
    "        movies_metadata_df = pd.read_csv(zip_ref.open(zip_ref.namelist()[0]), low_memory=False)\n",
    "\n",
    "    with zipfile.ZipFile(credits_zip_path, 'r') as zip_ref:\n",
    "        credits_df = pd.read_csv(zip_ref.open(zip_ref.namelist()[0]))\n",
    "\n",
    "    links_df = pd.read_csv(links_csv_path)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: One or more required CSV/ZIP files not found. Please ensure they are in the correct directory.\")\n",
    "    print(f\"Missing file: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "movies_metadata_df['id'] = pd.to_numeric(movies_metadata_df['id'], errors='coerce')\n",
    "movies_metadata_df.dropna(subset=['id'], inplace=True)\n",
    "movies_metadata_df['id'] = movies_metadata_df['id'].astype(int)\n",
    "\n",
    "links_df['tmdbId'] = pd.to_numeric(links_df['tmdbId'], errors='coerce')\n",
    "links_df.dropna(subset=['tmdbId'], inplace=True)\n",
    "links_df['tmdbId'] = links_df['tmdbId'].astype(int)\n",
    "\n",
    "valid_ids = set(links_df['tmdbId'])\n",
    "movies_metadata_filtered = movies_metadata_df[movies_metadata_df['id'].isin(valid_ids)]\n",
    "credits_filtered = credits_df[credits_df['id'].isin(valid_ids)]\n",
    "keywords_filtered = keywords_df[keywords_df['id'].isin(valid_ids)]\n",
    "\n",
    "master_dataset = movies_metadata_filtered.merge(credits_filtered, on='id', how='left')\n",
    "master_dataset = master_dataset.merge(keywords_filtered, on='id', how='left')\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "for col in ['cast', 'crew', 'keywords', 'genres']:\n",
    "    master_dataset[col] = master_dataset[col].fillna('[]').apply(safe_literal_eval)\n",
    "\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if isinstance(i, dict) and i.get('job') == 'Director':\n",
    "            return i.get('name')\n",
    "    return np.nan\n",
    "\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(\n",
    "    lambda x: [i.get('name') for i in x[:3] if isinstance(i, dict) and i.get('name')] if isinstance(x, list) else []\n",
    ")\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(\n",
    "    lambda x: [i.get('name') for i in x if isinstance(i, dict) and i.get('name')] if isinstance(x, list) else []\n",
    ")\n",
    "master_dataset['director'] = master_dataset['crew'].apply(get_director)\n",
    "\n",
    "master_dataset['cast'] = master_dataset['cast'].apply(lambda x: [s.lower().replace(\" \", \"\") for s in x])\n",
    "master_dataset['main_director'] = master_dataset['director']\n",
    "master_dataset['director'] = master_dataset['director'].astype(str).apply(lambda x: [x.lower().replace(\" \", \"\")] * 3)\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "master_dataset['keywords'] = master_dataset['keywords'].apply(\n",
    "    lambda x: [stemmer.stem(s).lower().replace(\" \", \"\") for s in x if len(s) > 1]\n",
    ")\n",
    "\n",
    "master_dataset['genres'] = master_dataset['genres'].apply(\n",
    "    lambda x: [g.get('name') for g in x if isinstance(g, dict) and g.get('name')] if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "for col in ['keywords', 'cast', 'director', 'genres']:\n",
    "    master_dataset[col] = master_dataset[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "master_dataset['soup'] = master_dataset['keywords'] + master_dataset['cast'] + master_dataset['director'] + master_dataset['genres']\n",
    "master_dataset['soup'] = master_dataset['soup'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "columns_to_keep = ['title', 'main_director', 'release_date', 'soup', 'popularity']\n",
    "master_dataset_final = master_dataset[columns_to_keep].copy()\n",
    "\n",
    "master_dataset_final['popularity'] = pd.to_numeric(master_dataset_final['popularity'], errors='coerce')\n",
    "master_dataset_final.dropna(subset=['popularity'], inplace=True)\n",
    "\n",
    "master_dataset_final['main_director'] = master_dataset_final['main_director'].apply(\n",
    "    lambda x: x if isinstance(x, str) and len(x) > 1 else np.nan\n",
    ")\n",
    "master_dataset_final.dropna(subset=['main_director'], inplace=True)\n",
    "\n",
    "master_dataset_final.sort_values(by='popularity', ascending=False, inplace=True)\n",
    "master_dataset_final.drop('popularity', axis=1, inplace=True)\n",
    "\n",
    "master_dataset_final.reset_index(drop=True, inplace=True)\n",
    "master_dataset_final['release_date'] = master_dataset_final['release_date'].apply(\n",
    "    lambda x: x if isinstance(x, str) and len(x) > 1 else np.nan\n",
    ")\n",
    "master_dataset_final.dropna(subset=['release_date'], inplace=True)\n",
    "\n",
    "master_dataset_final = master_dataset_final.head(2500)\n",
    "\n",
    "print(f\"Shape of the final dataset for recommendations: {master_dataset_final.shape}\")\n",
    "print(master_dataset_final.head())\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2), min_df=5)\n",
    "\n",
    "count_matrix = count_vectorizer.fit_transform(master_dataset_final['soup'])\n",
    "\n",
    "print(f\"\\nShape of the Count Matrix: {count_matrix.shape}\")\n",
    "\n",
    "print(\"\\nComputing Cosine Similarity Matrix...\")\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "print(\"Cosine Similarity Matrix Computed.\")\n",
    "\n",
    "np.savetxt('cosine_similarity_matrix.csv', cosine_sim, delimiter=',')\n",
    "print(\"Cosine Similarity Matrix saved to 'cosine_similarity_matrix.csv'\")\n",
    "\n",
    "indices = pd.Series(master_dataset_final.index, index=master_dataset_final['title']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(movie_title, cosine_sim_matrix, df, num_recommendations=10):\n",
    "    if movie_title not in indices:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    idx = indices[movie_title]\n",
    "    sim_scores = sorted(list(enumerate(cosine_sim_matrix[idx])), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    recommendations = []\n",
    "    for i in movie_indices:\n",
    "        movie_info = df.iloc[i]\n",
    "        recommendations.append({\n",
    "            'title': movie_info['title'],\n",
    "            'director': movie_info['main_director'],\n",
    "            'release_date': movie_info['release_date']\n",
    "        })\n",
    "    return recommendations\n",
    "\n",
    "print(\"\\n--- Movie Recommendations ---\")\n",
    "\n",
    "movie_to_recommend = \"Minions\"\n",
    "recommended_movies = get_recommendations(movie_to_recommend, cosine_sim, master_dataset_final)\n",
    "\n",
    "if recommended_movies:\n",
    "    print(f\"\\nRecommended movies for \\\"{movie_to_recommend}\\\":\")\n",
    "    for movie in recommended_movies:\n",
    "        print(f\"- Title: {movie['title']}\")\n",
    "        print(f\"  Director: {movie['director']}\")\n",
    "        print(f\"  Release Date: {movie['release_date']}\")\n",
    "        print()\n",
    "\n",
    "movie_to_recommend_avatar = \"Avatar\"\n",
    "recommended_movies_avatar = get_recommendations(movie_to_recommend_avatar, cosine_sim, master_dataset_final)\n",
    "\n",
    "if recommended_movies_avatar:\n",
    "    print(f\"\\nRecommended movies for \\\"{movie_to_recommend_avatar}\\\":\")\n",
    "    for movie in recommended_movies_avatar:\n",
    "        print(f\"- Title: {movie['title']}\")\n",
    "        print(f\"  Director: {movie['director']}\")\n",
    "        print(f\"  Release Date: {movie['release_date']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed64ffd-f318-4382-b99f-248e9f98e49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
